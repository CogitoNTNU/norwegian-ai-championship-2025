{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a6cc0993",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Keep modules up to date every time you hit Shift-Enter \n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c9051803",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WANDB_API_KEY: ac37...\n",
      "MONAI version: 1.4.0\n",
      "Numpy version: 1.26.4\n",
      "Pytorch version: 2.7.1+cu126\n",
      "MONAI flags: HAS_EXT = False, USE_COMPILED = False, USE_META_DICT = False\n",
      "MONAI rev id: 46a5272196a6c2590ca2589029eed8e4d56ff008\n",
      "MONAI __file__: /media/<username>/AI-Mesterskap/norwegian-ai-championship-2025/segmentation/.venv/lib/python3.11/site-packages/monai/__init__.py\n",
      "\n",
      "Optional dependencies:\n",
      "Pytorch Ignite version: 0.4.11\n",
      "ITK version: 5.4.4\n",
      "Nibabel version: 5.3.2\n",
      "scikit-image version: 0.25.2\n",
      "scipy version: 1.16.1\n",
      "Pillow version: 11.3.0\n",
      "Tensorboard version: 2.20.0\n",
      "gdown version: 5.2.0\n",
      "TorchVision version: 0.22.1+cu126\n",
      "tqdm version: 4.67.1\n",
      "lmdb version: 1.7.3\n",
      "psutil version: 7.0.0\n",
      "pandas version: 2.3.1\n",
      "einops version: 0.8.1\n",
      "transformers version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "mlflow version: 3.1.4\n",
      "pynrrd version: 1.1.3\n",
      "clearml version: NOT INSTALLED or UNKNOWN VERSION.\n",
      "\n",
      "For details about installing the optional dependencies, please visit:\n",
      "    https://docs.monai.io/en/latest/installation.html#installing-the-recommended-dependencies\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.21.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/media/mina-aldolaimi/AI-Mesterskap/norwegian-ai-championship-2025/segmentation/wandb/run-20250803_210122-lcet4akr</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/nm-i-ki/tumor-segmentation/runs/lcet4akr' target=\"_blank\">unet_20250803_210122</a></strong> to <a href='https://wandb.ai/nm-i-ki/tumor-segmentation' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/nm-i-ki/tumor-segmentation' target=\"_blank\">https://wandb.ai/nm-i-ki/tumor-segmentation</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/nm-i-ki/tumor-segmentation/runs/lcet4akr' target=\"_blank\">https://wandb.ai/nm-i-ki/tumor-segmentation/runs/lcet4akr</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m When using several event log directories, please call `wandb.tensorboard.patch(root_logdir=\"...\")` before `wandb.init`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 426 control images.\n",
      "Found 182 patient images.\n",
      "Randomly selected 182 control samples from 426 available.\n",
      "Final dataset: 182 patients + 182 controls = 364 samples (50/50 split)\n",
      "Amount of images train: 328 val: 36\n",
      "Starting training...\n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Num foregrounds 195600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 176800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 353200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 135600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 185200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 371200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 170400, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 189600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 168400, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 270400, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 340800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 191200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 184000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 164400, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 175600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 170800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 169200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 172800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 220800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 143200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 356800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 180000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 190800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 198000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 178000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 187200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 180400, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 366400, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 346000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 168000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 182800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 175200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 188800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 346800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 181600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 177600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 320800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 179200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 182400, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 145200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 295600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 355200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 145600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 155200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 338800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 199200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 160800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 198400, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 193200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 196000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 194400, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 157600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 211600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 218800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 358000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 343600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 157200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 350400, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 245200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 335200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 193600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 204000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 298000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 192000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 141600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 205200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 359200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 322800, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 389200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 321600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 210000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 120000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 163200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 200400, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 187600, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 316000, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n",
      "Num foregrounds 139200, Num backgrounds 0, unable to generate class balanced samples, setting `pos_ratio` to 1.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Train avg loss: 0.7934\n",
      "\n",
      "Epoch 2/100\n",
      "  Train avg loss: 0.7793\n",
      "  Val mean Dice: 0.2958\n",
      "  Best model saved with Dice 0.2958 at epoch 2\n",
      "\n",
      "Epoch 3/100\n",
      "  Train avg loss: 0.7744\n",
      "\n",
      "Epoch 4/100\n",
      "  Train avg loss: 0.7668\n",
      "  Val mean Dice: 0.2931\n",
      "\n",
      "Epoch 5/100\n",
      "  Train avg loss: 0.7614\n",
      "\n",
      "Epoch 6/100\n",
      "  Train avg loss: 0.7565\n",
      "  Val mean Dice: 0.2964\n",
      "  Best model saved with Dice 0.2964 at epoch 6\n",
      "\n",
      "Epoch 7/100\n",
      "  Train avg loss: 0.7537\n",
      "\n",
      "Epoch 8/100\n",
      "  Train avg loss: 0.7509\n",
      "  Val mean Dice: 0.3031\n",
      "  Best model saved with Dice 0.3031 at epoch 8\n",
      "\n",
      "Epoch 9/100\n",
      "  Train avg loss: 0.7487\n",
      "\n",
      "Epoch 10/100\n",
      "  Train avg loss: 0.7467\n",
      "  Val mean Dice: 0.3070\n",
      "  Best model saved with Dice 0.3070 at epoch 10\n",
      "\n",
      "Epoch 11/100\n",
      "  Train avg loss: 0.7440\n",
      "\n",
      "Epoch 12/100\n",
      "  Train avg loss: 0.7424\n",
      "  Val mean Dice: 0.3225\n",
      "  Best model saved with Dice 0.3225 at epoch 12\n",
      "\n",
      "Epoch 13/100\n",
      "  Train avg loss: 0.7410\n",
      "\n",
      "Epoch 14/100\n",
      "  Train avg loss: 0.7378\n",
      "  Val mean Dice: 0.3407\n",
      "  Best model saved with Dice 0.3407 at epoch 14\n",
      "\n",
      "Epoch 15/100\n",
      "  Train avg loss: 0.7401\n",
      "\n",
      "Epoch 16/100\n",
      "  Train avg loss: 0.7349\n",
      "  Val mean Dice: 0.3615\n",
      "  Best model saved with Dice 0.3615 at epoch 16\n",
      "\n",
      "Epoch 17/100\n",
      "  Train avg loss: 0.7326\n",
      "\n",
      "Epoch 18/100\n",
      "  Train avg loss: 0.7312\n",
      "  Val mean Dice: 0.3889\n",
      "  Best model saved with Dice 0.3889 at epoch 18\n",
      "\n",
      "Epoch 19/100\n",
      "  Train avg loss: 0.7318\n",
      "\n",
      "Epoch 20/100\n",
      "  Train avg loss: 0.7282\n",
      "  Val mean Dice: 0.4132\n",
      "  Best model saved with Dice 0.4132 at epoch 20\n",
      "\n",
      "Epoch 21/100\n",
      "  Train avg loss: 0.7288\n",
      "\n",
      "Epoch 22/100\n",
      "  Train avg loss: 0.7306\n",
      "  Val mean Dice: 0.4207\n",
      "  Best model saved with Dice 0.4207 at epoch 22\n",
      "\n",
      "Epoch 23/100\n",
      "  Train avg loss: 0.7260\n",
      "\n",
      "Epoch 24/100\n",
      "  Train avg loss: 0.7258\n",
      "  Val mean Dice: 0.4451\n",
      "  Best model saved with Dice 0.4451 at epoch 24\n",
      "\n",
      "Epoch 25/100\n",
      "  Train avg loss: 0.7249\n",
      "\n",
      "Epoch 26/100\n",
      "  Train avg loss: 0.7219\n",
      "  Val mean Dice: 0.4832\n",
      "  Best model saved with Dice 0.4832 at epoch 26\n",
      "\n",
      "Epoch 27/100\n",
      "  Train avg loss: 0.7217\n",
      "\n",
      "Epoch 28/100\n",
      "  Train avg loss: 0.7247\n",
      "  Val mean Dice: 0.4679\n",
      "\n",
      "Epoch 29/100\n",
      "  Train avg loss: 0.7200\n",
      "\n",
      "Epoch 30/100\n",
      "  Train avg loss: 0.7241\n",
      "  Val mean Dice: 0.4725\n",
      "\n",
      "Epoch 31/100\n",
      "  Train avg loss: 0.7193\n",
      "\n",
      "Epoch 32/100\n",
      "  Train avg loss: 0.7178\n",
      "  Val mean Dice: 0.4705\n",
      "\n",
      "Epoch 33/100\n",
      "  Train avg loss: 0.7131\n",
      "\n",
      "Epoch 34/100\n",
      "  Train avg loss: 0.7110\n",
      "  Val mean Dice: 0.4905\n",
      "  Best model saved with Dice 0.4905 at epoch 34\n",
      "\n",
      "Epoch 35/100\n",
      "  Train avg loss: 0.7104\n",
      "\n",
      "Epoch 36/100\n",
      "  Train avg loss: 0.7117\n",
      "  Val mean Dice: 0.5009\n",
      "  Best model saved with Dice 0.5009 at epoch 36\n",
      "\n",
      "Epoch 37/100\n",
      "  Train avg loss: 0.7132\n",
      "\n",
      "Epoch 38/100\n",
      "  Train avg loss: 0.7137\n",
      "  Val mean Dice: 0.5159\n",
      "  Best model saved with Dice 0.5159 at epoch 38\n",
      "\n",
      "Epoch 39/100\n",
      "  Train avg loss: 0.7089\n",
      "\n",
      "Epoch 40/100\n",
      "  Train avg loss: 0.7097\n",
      "  Val mean Dice: 0.5364\n",
      "  Best model saved with Dice 0.5364 at epoch 40\n",
      "\n",
      "Epoch 41/100\n",
      "  Train avg loss: 0.7062\n",
      "\n",
      "Epoch 42/100\n",
      "  Train avg loss: 0.7050\n",
      "  Val mean Dice: 0.5491\n",
      "  Best model saved with Dice 0.5491 at epoch 42\n",
      "\n",
      "Epoch 43/100\n",
      "  Train avg loss: 0.7111\n",
      "\n",
      "Epoch 44/100\n",
      "  Train avg loss: 0.6995\n",
      "  Val mean Dice: 0.5658\n",
      "  Best model saved with Dice 0.5658 at epoch 44\n",
      "\n",
      "Epoch 45/100\n",
      "  Train avg loss: 0.7065\n",
      "\n",
      "Epoch 46/100\n",
      "  Train avg loss: 0.7060\n",
      "  Val mean Dice: 0.5369\n",
      "\n",
      "Epoch 47/100\n",
      "  Train avg loss: 0.6998\n",
      "\n",
      "Epoch 48/100\n",
      "  Train avg loss: 0.6999\n",
      "  Val mean Dice: 0.5301\n",
      "\n",
      "Epoch 49/100\n",
      "  Train avg loss: 0.7047\n",
      "\n",
      "Epoch 50/100\n",
      "  Train avg loss: 0.7015\n",
      "  Val mean Dice: 0.5524\n",
      "\n",
      "Epoch 51/100\n",
      "  Train avg loss: 0.6931\n",
      "\n",
      "Epoch 52/100\n",
      "  Train avg loss: 0.6997\n",
      "  Val mean Dice: 0.5316\n",
      "\n",
      "Epoch 53/100\n",
      "  Train avg loss: 0.6953\n",
      "\n",
      "Epoch 54/100\n",
      "  Train avg loss: 0.6965\n",
      "  Val mean Dice: 0.5512\n",
      "\n",
      "Epoch 55/100\n",
      "  Train avg loss: 0.6989\n",
      "\n",
      "Epoch 56/100\n",
      "  Train avg loss: 0.6958\n",
      "  Val mean Dice: 0.5892\n",
      "  Best model saved with Dice 0.5892 at epoch 56\n",
      "\n",
      "Epoch 57/100\n",
      "  Train avg loss: 0.6971\n",
      "\n",
      "Epoch 58/100\n",
      "  Train avg loss: 0.6973\n",
      "  Val mean Dice: 0.5805\n",
      "\n",
      "Epoch 59/100\n",
      "  Train avg loss: 0.6970\n",
      "\n",
      "Epoch 60/100\n",
      "  Train avg loss: 0.6930\n",
      "  Val mean Dice: 0.5969\n",
      "  Best model saved with Dice 0.5969 at epoch 60\n",
      "\n",
      "Epoch 61/100\n",
      "  Train avg loss: 0.6961\n",
      "\n",
      "Epoch 62/100\n",
      "  Train avg loss: 0.6910\n",
      "  Val mean Dice: 0.6051\n",
      "  Best model saved with Dice 0.6051 at epoch 62\n",
      "\n",
      "Epoch 63/100\n",
      "  Train avg loss: 0.6898\n",
      "\n",
      "Epoch 64/100\n",
      "  Train avg loss: 0.6908\n",
      "  Val mean Dice: 0.5635\n",
      "\n",
      "Epoch 65/100\n",
      "  Train avg loss: 0.6967\n",
      "\n",
      "Epoch 66/100\n",
      "  Train avg loss: 0.6960\n",
      "  Val mean Dice: 0.5976\n",
      "\n",
      "Epoch 67/100\n",
      "  Train avg loss: 0.6889\n",
      "\n",
      "Epoch 68/100\n",
      "  Train avg loss: 0.6896\n",
      "  Val mean Dice: 0.6321\n",
      "  Best model saved with Dice 0.6321 at epoch 68\n",
      "\n",
      "Epoch 69/100\n",
      "  Train avg loss: 0.6929\n",
      "\n",
      "Epoch 70/100\n",
      "  Train avg loss: 0.6968\n",
      "  Val mean Dice: 0.6136\n",
      "\n",
      "Epoch 71/100\n",
      "  Train avg loss: 0.6892\n",
      "\n",
      "Epoch 72/100\n",
      "  Train avg loss: 0.6875\n",
      "  Val mean Dice: 0.5794\n",
      "\n",
      "Epoch 73/100\n",
      "  Train avg loss: 0.6921\n",
      "\n",
      "Epoch 74/100\n",
      "  Train avg loss: 0.6891\n",
      "  Val mean Dice: 0.5989\n",
      "\n",
      "Epoch 75/100\n",
      "  Train avg loss: 0.6945\n",
      "\n",
      "Epoch 76/100\n",
      "  Train avg loss: 0.6865\n",
      "  Val mean Dice: 0.6127\n",
      "\n",
      "Epoch 77/100\n",
      "  Train avg loss: 0.6889\n",
      "\n",
      "Epoch 78/100\n",
      "  Train avg loss: 0.6895\n",
      "  Val mean Dice: 0.5869\n",
      "\n",
      "Epoch 79/100\n",
      "  Train avg loss: 0.6898\n",
      "\n",
      "Epoch 80/100\n",
      "  Train avg loss: 0.6861\n",
      "  Val mean Dice: 0.6458\n",
      "  Best model saved with Dice 0.6458 at epoch 80\n",
      "\n",
      "Epoch 81/100\n",
      "  Train avg loss: 0.6902\n",
      "\n",
      "Epoch 82/100\n",
      "  Train avg loss: 0.6896\n",
      "  Val mean Dice: 0.6387\n",
      "\n",
      "Epoch 83/100\n",
      "  Train avg loss: 0.6836\n",
      "\n",
      "Epoch 84/100\n",
      "  Train avg loss: 0.6934\n",
      "  Val mean Dice: 0.6166\n",
      "\n",
      "Epoch 85/100\n",
      "  Train avg loss: 0.6846\n",
      "\n",
      "Epoch 86/100\n",
      "  Train avg loss: 0.6846\n",
      "  Val mean Dice: 0.6196\n",
      "\n",
      "Epoch 87/100\n",
      "  Train avg loss: 0.6846\n",
      "\n",
      "Epoch 88/100\n",
      "  Train avg loss: 0.6813\n",
      "  Val mean Dice: 0.6124\n",
      "\n",
      "Epoch 89/100\n",
      "  Train avg loss: 0.6819\n",
      "\n",
      "Epoch 90/100\n",
      "  Train avg loss: 0.6879\n",
      "  Val mean Dice: 0.6657\n",
      "  Best model saved with Dice 0.6657 at epoch 90\n",
      "\n",
      "Epoch 91/100\n",
      "  Train avg loss: 0.6899\n",
      "\n",
      "Epoch 92/100\n",
      "  Train avg loss: 0.6897\n",
      "  Val mean Dice: 0.6487\n",
      "\n",
      "Epoch 93/100\n",
      "  Train avg loss: 0.6841\n",
      "\n",
      "Epoch 94/100\n",
      "  Train avg loss: 0.6869\n",
      "  Val mean Dice: 0.6785\n",
      "  Best model saved with Dice 0.6785 at epoch 94\n",
      "\n",
      "Epoch 95/100\n",
      "  Train avg loss: 0.6932\n",
      "\n",
      "Epoch 96/100\n",
      "  Train avg loss: 0.6851\n",
      "  Val mean Dice: 0.6189\n",
      "\n",
      "Epoch 97/100\n",
      "  Train avg loss: 0.6923\n",
      "\n",
      "Epoch 98/100\n",
      "  Train avg loss: 0.6807\n",
      "  Val mean Dice: 0.6438\n",
      "\n",
      "Epoch 99/100\n",
      "  Train avg loss: 0.6925\n",
      "\n",
      "Epoch 100/100\n",
      "  Train avg loss: 0.6851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m The nbformat package was not found. It is required to save notebook history.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Val mean Dice: 0.6238\n",
      "\n",
      "Training done! Best Dice 0.6785 reached on epoch 94\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>▁▂▂▂▂▃▃▃▄▄▄▄▄▅▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇█████</td></tr><tr><td>global_step</td><td>▁▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▁▅▅▅▆▆▆▆▆▇▇▇▇▇████▁</td></tr><tr><td>step</td><td>▁▁▁▁▂▂▂▂▂▂▃▃▃▃▃▄▄▄▄▄▅▅▅▅▅▆▆▆▆▆▇▇▇▇▇▇████</td></tr><tr><td>train_avg_loss</td><td>█▇▇▆▆▆▅▅▅▅▄▄▄▄▃▃▃▂▃▂▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▂▁▁▂▂</td></tr><tr><td>train_loss</td><td>███▇▇▆▇▇▇▇▇▇▃▆▇▇▃▆▇▆▅▁▂▇▂▂▇▇▄▄▇▅▁▃▇▂▄▇▇▄</td></tr><tr><td>val_mean_dice</td><td>▁▁▁▁▁▂▃▃▃▄▄▄▄▄▄▅▅▆▆▆▅▅▆▆▆▇▇▆▇▇▆▇▇▇▇▇█▇█▇</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>epoch</td><td>100</td></tr><tr><td>global_step</td><td>100</td></tr><tr><td>step</td><td>16400</td></tr><tr><td>train_avg_loss</td><td>0.68507</td></tr><tr><td>train_loss</td><td>0.75</td></tr><tr><td>val_mean_dice</td><td>0.62376</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">unet_20250803_210122</strong> at: <a href='https://wandb.ai/nm-i-ki/tumor-segmentation/runs/lcet4akr' target=\"_blank\">https://wandb.ai/nm-i-ki/tumor-segmentation/runs/lcet4akr</a><br> View project at: <a href='https://wandb.ai/nm-i-ki/tumor-segmentation' target=\"_blank\">https://wandb.ai/nm-i-ki/tumor-segmentation</a><br>Synced 6 W&B file(s), 300 media file(s), 52 artifact file(s) and 1 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>./wandb/run-20250803_210122-lcet4akr/logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import logging\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "from dotenv import load_dotenv\n",
    "import torch\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "import monai\n",
    "from monai.data import list_data_collate, decollate_batch, DataLoader\n",
    "from monai.inferers import sliding_window_inference\n",
    "from monai.metrics import DiceMetric\n",
    "from monai.transforms import (\n",
    "    Activations,\n",
    "    RandAffined,\n",
    "    AsDiscrete,\n",
    "    Compose,\n",
    "    Rand2DElasticd,\n",
    "    RandShiftIntensityd,\n",
    ")\n",
    "from monai.visualize import plot_2d_or_3d_image\n",
    "import wandb\n",
    "from tumor_dataset import create_tumor_dataset\n",
    "\n",
    "\n",
    "\n",
    "def main(dataset_dir):\n",
    "    logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "    monai.config.print_config()\n",
    "    \n",
    "    NUM_EPOCHS = 100\n",
    "    BATCH_SIZE = 2\n",
    "    LR = 1e-4\n",
    "    PATCH_SIZE = (128, 128)\n",
    "\n",
    "    # W&B run initialization\n",
    "    run = wandb.init(\n",
    "        project=\"tumor-segmentation\",\n",
    "        entity=\"nm-i-ki\",\n",
    "        name=f\"unet_{datetime.now():%Y%m%d_%H%M%S}\",\n",
    "        config=dict(\n",
    "            num_epochs=NUM_EPOCHS,\n",
    "            batch_size=BATCH_SIZE,\n",
    "            learning_rate=LR,\n",
    "            patch_size=PATCH_SIZE,\n",
    "            architecture=\"UNet\",\n",
    "            loss=\"Dice(sigmoid=True)\",\n",
    "            optimizer=\"Adam\",\n",
    "        ),\n",
    "        save_code=True,\n",
    "        sync_tensorboard=True,\n",
    "        tags=[\"monai\", \"segmentation\"],\n",
    "    )\n",
    "\n",
    "    # Train transforms\n",
    "    train_transforms = [\n",
    "        RandAffined(\n",
    "            keys=[\"img\", \"seg\"],\n",
    "            mode=[\"bilinear\", \"nearest\"],\n",
    "            spatial_size=PATCH_SIZE,\n",
    "\n",
    "            rotate_range=(np.pi / 20, np.pi / 20),\n",
    "            scale_range=(0.1, 0.1),\n",
    "            translate_range=(-10, 10),\n",
    "            padding_mode=\"border\",\n",
    "        ),\n",
    "        Rand2DElasticd(\n",
    "            keys=[\"img\", \"seg\"],\n",
    "            spacing=(24, 24),\n",
    "            magnitude_range=(1, 10),\n",
    "            mode=[\"bilinear\", \"nearest\"],\n",
    "            spatial_size=PATCH_SIZE,\n",
    "\n",
    "            rotate_range=(0.1, 0.1),\n",
    "            scale_range=(0.1, 0.1),\n",
    "            translate_range=(-10, 10),\n",
    "        ),\n",
    "        RandShiftIntensityd(\n",
    "            keys=[\"img\"],\n",
    "            offsets=0.25,\n",
    "            safe=True,\n",
    "            channel_wise=False\n",
    "        )\n",
    "    ]\n",
    "\n",
    "    # Create datasets\n",
    "    train_ds, val_ds = create_tumor_dataset(dataset_dir=dataset_dir, train_data_augmentation=train_transforms)\n",
    "\n",
    "    print(f\"Amount of images train: {len(train_ds)} val: {len(val_ds)}\")\n",
    "    train_loader = DataLoader(\n",
    "        train_ds,\n",
    "        batch_size=BATCH_SIZE,\n",
    "        shuffle=True,\n",
    "        collate_fn=list_data_collate,\n",
    "        pin_memory=torch.cuda.is_available(),\n",
    "    )\n",
    "    val_loader = DataLoader(val_ds, batch_size=1, collate_fn=list_data_collate)\n",
    "\n",
    "    # Model, loss, optimizer\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = monai.networks.nets.UNet(\n",
    "        spatial_dims=2,\n",
    "        in_channels=4,\n",
    "        out_channels=4,\n",
    "        channels=(16, 32, 64, 128, 256),\n",
    "        strides=(2, 2, 2, 2),\n",
    "        num_res_units=2,\n",
    "    ).to(device)\n",
    "    loss_function = monai.losses.DiceLoss(sigmoid=True)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), LR)\n",
    "\n",
    "    # Attach gradients & parameters to W&B\n",
    "    wandb.watch(model, log=\"all\", log_freq=10)\n",
    "\n",
    "    # Train model\n",
    "    print(\"Starting training...\")\n",
    "    dice_metric = DiceMetric(include_background=True, reduction=\"mean\")\n",
    "    post_trans = Compose([Activations(sigmoid=True), AsDiscrete(threshold=0.5)])\n",
    "    tensorboard_writer = SummaryWriter()\n",
    "    best_metric = -1.0\n",
    "    best_epoch = -1\n",
    "\n",
    "    os.makedirs(\"models\", exist_ok=True)\n",
    "    global_step = 0\n",
    "\n",
    "    for epoch in range(NUM_EPOCHS):\n",
    "        print(f\"\\nEpoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "        model.train()\n",
    "        epoch_loss = 0\n",
    "        for step, batch in enumerate(train_loader, 1):\n",
    "            imgs, segs = batch[\"img\"].to(device), batch[\"seg\"].to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(imgs)\n",
    "            loss = loss_function(outputs, segs)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            epoch_loss += loss.item()\n",
    "\n",
    "            # Log per step\n",
    "            global_step += 1\n",
    "            wandb.log({\"train_loss\": loss.item(), \"epoch\": epoch + 1, \"step\": global_step})\n",
    "            tensorboard_writer.add_scalar(\n",
    "                \"train_loss\", loss.item(), epoch * len(train_loader) + step\n",
    "            )\n",
    "        avg_epoch_loss = epoch_loss / step\n",
    "        print(f\"  Train avg loss: {avg_epoch_loss:.4f}\")\n",
    "        wandb.log({\"train_avg_loss\": avg_epoch_loss, \"epoch\": epoch + 1})\n",
    "\n",
    "        if (epoch + 1) % 2 == 0:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for val_batch in val_loader:\n",
    "                    val_imgs, val_segs = val_batch[\"img\"].to(device), val_batch[\"seg\"].to(device)\n",
    "                    sw_out = sliding_window_inference(val_imgs, PATCH_SIZE, 4, model)\n",
    "                    preds = [post_trans(x) for x in decollate_batch(sw_out)]\n",
    "                    dice_metric(y_pred=preds, y=val_segs)\n",
    "                metric = dice_metric.aggregate().item()\n",
    "                dice_metric.reset()\n",
    "                tensorboard_writer.add_scalar(\"val_mean_dice\", metric, epoch + 1)\n",
    "                print(f\"  Val mean Dice: {metric:.4f}\")\n",
    "\n",
    "                # Log validation metric & sample images\n",
    "                wandb.log({\"val_mean_dice\": metric, \"epoch\": epoch + 1})\n",
    "\n",
    "                # Log first channel of first image / pred / label as examples\n",
    "                img_np = val_imgs[0, 0].cpu().float().numpy()\n",
    "                pred_np = preds[0][0].cpu().float().numpy()\n",
    "                label_np = val_segs[0, 0].cpu().float().numpy()\n",
    "                wandb.log(\n",
    "                    {\n",
    "                        \"example_input\": wandb.Image(img_np, caption=\"input\"),\n",
    "                        \"example_pred\": wandb.Image(pred_np, caption=\"prediction\"),\n",
    "                        \"example_label\": wandb.Image(label_np, caption=\"ground truth\"),\n",
    "                        \"epoch\": epoch + 1,\n",
    "                    }\n",
    "                )\n",
    "\n",
    "                if metric > best_metric:\n",
    "                    best_metric = metric\n",
    "                    best_epoch = epoch + 1\n",
    "                    best_model_path = f\"models/best_model_{metric:.4f}.pth\"\n",
    "                    torch.save(model.state_dict(), best_model_path)\n",
    "                    print(\n",
    "                        f\"  Best model saved with Dice {best_metric:.4f} at epoch {best_epoch}\"\n",
    "                    )\n",
    "\n",
    "                    # Save model to W&B as an artifact\n",
    "                    artifact = wandb.Artifact(\"best_model\", type=\"model\")\n",
    "                    artifact.add_file(best_model_path)\n",
    "                    run.log_artifact(artifact)\n",
    "\n",
    "                # Continue logging to TensorBoard if desired\n",
    "                plot_2d_or_3d_image(val_imgs, epoch + 1, tensorboard_writer, index=0, tag=\"image\")\n",
    "                plot_2d_or_3d_image(val_segs, epoch + 1, tensorboard_writer, index=0, tag=\"label\")\n",
    "                plot_2d_or_3d_image(preds, epoch + 1, tensorboard_writer, index=0, tag=\"output\")\n",
    "\n",
    "    print(\n",
    "        f\"\\nTraining done! Best Dice {best_metric:.4f} reached on epoch {best_epoch}\"\n",
    "    )\n",
    "    tensorboard_writer.close()\n",
    "    run.finish()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    load_dotenv()  # Load environment variables from .env file\n",
    "    WANDB_API_KEY = os.getenv(\"WANDB_API_KEY\")\n",
    "    if not WANDB_API_KEY:\n",
    "        raise ValueError(\"WANDB_API_KEY not found in environment variables. Please set it in .env file.\")\n",
    "    print(f\"WANDB_API_KEY: {WANDB_API_KEY[:4]}...\")  # Print only the first 4 characters for security\n",
    "    main(\"../data/raw/tumor-segmentation\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tumor-segmentation",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
