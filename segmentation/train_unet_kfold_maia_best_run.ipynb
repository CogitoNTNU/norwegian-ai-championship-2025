{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3815,
     "status": "ok",
     "timestamp": 1754554541457,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "B6byInL7VsxG",
    "outputId": "e0464037-38fb-4f5e-b91c-e4d5ad4f3fbf"
   },
   "outputs": [],
   "source": [
    "%pip install numpy pandas matplotlib scikit-learn scikit-image seaborn plotly timm albumentations torch torchvision torchaudio colorama segmentation-models-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1122,
     "status": "ok",
     "timestamp": 1754554542581,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "xPEUJ2w8VsxG"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "# pd.options.plotting.backend = \"plotly\"\n",
    "import random\n",
    "from glob import glob\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "tqdm.pandas()\n",
    "\n",
    "from dataclasses import dataclass\n",
    "\n",
    "\n",
    "# visualization\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedGroupKFold\n",
    "\n",
    "# PyTorch\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim import lr_scheduler\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.cuda import amp\n",
    "from torch.cuda.amp import autocast, GradScaler\n",
    "from torch.optim import Optimizer\n",
    "\n",
    "# Albumentations for augmentations\n",
    "import albumentations as A\n",
    "from albumentations.augmentations.crops.transforms import RandomCrop\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "\n",
    "# Add Monitoring and Logging\n",
    "import wandb\n",
    "from datetime import datetime\n",
    "\n",
    "# For colored terminal text\n",
    "from colorama import Fore, Back, Style\n",
    "c_  = Fore.GREEN\n",
    "sr_ = Style.RESET_ALL\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# For descriptive error messages\n",
    "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
    "\n",
    "from google.colab import userdata\n",
    "WANDB_API_KEY = userdata.get('WANDB_API_KEY')\n",
    "if not WANDB_API_KEY:\n",
    "    raise ValueError(\"WANDB_API_KEY environment variable is not set.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lHTFqPWmVsxI"
   },
   "source": [
    "# ⚙️ Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1754554542586,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "y6Aahcb1VsxI"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "@dataclass\n",
    "class CFG:\n",
    "    seed          = 2025\n",
    "    backbone      = \"efficientnet-b3\"# \"efficientnet-b3\" # se_resnext101_32x4d - se_resnext50_32x4d - efficientnet-b3  timm-resnest101e\n",
    "    decoder_attention_type = \"scse\"\n",
    "    train_bs      = 3\n",
    "    valid_bs      = train_bs*2\n",
    "    img_size      = [1536, 786]\n",
    "    crop_size     = [512, 512]\n",
    "    epochs        = 60 # 40\n",
    "    lr            = 1e-4\n",
    "    max_grad_norm = 100\n",
    "    scheduler     = \"ReduceLROnPlateau\" #'OneCycle' # ReduceLROnPlateau CosineAnnealingLR CustomCosineAnnealingWarmupRestarts\n",
    "    min_lr        = 5e-5\n",
    "    T_max         = int(17000/train_bs*epochs)+50\n",
    "    T_0           = 25\n",
    "    max_lr        = 4e-4\n",
    "    warmup_epochs = 0\n",
    "    wd            = 5e-6\n",
    "    n_accumulate  = 1\n",
    "    n_fold        = 4\n",
    "    folds         = [0, 1, 2, 3]\n",
    "    num_classes   = 1\n",
    "    device        = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "    aux_head      = False\n",
    "    thresh        = [0.3, 0.4, 0.5, 0.6, 0.7]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 158
    },
    "executionInfo": {
     "elapsed": 2117,
     "status": "ok",
     "timestamp": 1754554544704,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "eha4VTnXVsxI",
    "outputId": "80b6ca83-e86d-4b40-cb19-b6e640448b07"
   },
   "outputs": [],
   "source": [
    "# Initialize W&B run\n",
    "wandb.login(key=WANDB_API_KEY)\n",
    "run = wandb.init(\n",
    "    project=\"tumor-segmentation\",\n",
    "    entity=\"nm-i-ki\",\n",
    "    name=f\"train_unet_kfold_tta_{datetime.now():%Y%m%d_%H%M%S}\",\n",
    "    config={\n",
    "        \"seed\": CFG.seed,\n",
    "        \"backbone\": CFG.backbone,\n",
    "        \"decoder_attention_type\": CFG.decoder_attention_type,\n",
    "        \"train_bs\": CFG.train_bs,\n",
    "        \"valid_bs\": CFG.valid_bs,\n",
    "        \"img_size\": CFG.img_size,\n",
    "        \"crop_size\": CFG.crop_size,\n",
    "        \"epochs\": CFG.epochs,\n",
    "        \"lr\": CFG.lr,\n",
    "        \"max_grad_norm\": CFG.max_grad_norm,\n",
    "        \"scheduler\": CFG.scheduler,\n",
    "        \"min_lr\": CFG.min_lr,\n",
    "        \"T_max\": CFG.T_max,\n",
    "        \"T_0\": CFG.T_0,\n",
    "        \"max_lr\": CFG.max_lr,\n",
    "        \"warmup_epochs\": CFG.warmup_epochs,\n",
    "        \"wd\": CFG.wd,\n",
    "        \"n_accumulate\": CFG.n_accumulate,\n",
    "        \"n_fold\": CFG.n_fold,\n",
    "        \"folds\": CFG.folds,\n",
    "        \"num_classes\": CFG.num_classes,\n",
    "        \"aux_head\": CFG.aux_head,\n",
    "        \"thresh\": CFG.thresh,\n",
    "    },\n",
    "    tags=[\"segmentation\", \"efficientnet\"],\n",
    "    save_code=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4Zl66NmVsxI"
   },
   "source": [
    "# ❗ Reproducibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 847,
     "status": "ok",
     "timestamp": 1754554545553,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "0vQJRTeVVsxK",
    "outputId": "3a177880-360c-438c-89d9-e70382885f46"
   },
   "outputs": [],
   "source": [
    "def set_seed(seed = 42):\n",
    "    '''Sets the seed of the entire notebook so results are the same every time we run.\n",
    "    This is for REPRODUCIBILITY.'''\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    # When running on the CuDNN backend, two further options must be set\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    # Set a fixed value for the hash seed\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    print('-> SEEDING DONE')\n",
    "\n",
    "set_seed(CFG.seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3129,
     "status": "ok",
     "timestamp": 1754554548684,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "t8kVIIyOVsxK",
    "outputId": "200ef00d-2ead-4b16-f73d-302ce25dd037"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "# CONTROLS_DIR = \"/content/drive/MyDrive/data/raw/tumor-segmentation/controls/\"\n",
    "PATIENTS_DIR = \"/content/drive/MyDrive/data/raw/tumor-segmentation/patients\"\n",
    "\n",
    "rows = []\n",
    "data_df = pd.DataFrame(columns=['image_id', 'image_path', 'label_path', 'label'])\n",
    "\n",
    "# Load the control images\n",
    "# control_images = glob(os.path.join(CONTROLS_DIR, \"imgs\", \"*.png\"))\n",
    "# for img_path in control_images:\n",
    "#     image_id = os.path.basename(img_path).split('/')[-1]\n",
    "#     rows.append({'image_id': image_id, 'image_path': f'{CONTROLS_DIR}/imgs/{image_id}', 'label_path': '', 'label': 0})\n",
    "\n",
    "# Load the patient images\n",
    "patient_images = glob(os.path.join(PATIENTS_DIR, \"imgs\", \"*.png\"))\n",
    "segmentation_labels = glob(os.path.join(PATIENTS_DIR, \"labels\", \"*.png\"))\n",
    "for img_path, label_path in zip(patient_images, segmentation_labels):\n",
    "    image_id = os.path.basename(img_path).split('/')[-1]\n",
    "    label_id = image_id.replace('patient', 'segmentation')\n",
    "    rows.append({'image_id': image_id, 'image_path': f'{PATIENTS_DIR}/imgs/{image_id}', 'label_path': f'{PATIENTS_DIR}/labels/{label_id}', 'label': 1})\n",
    "\n",
    "data_df = pd.DataFrame(rows)\n",
    "data_df = data_df.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i-uT7q6lVsxK"
   },
   "source": [
    "## Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 147
    },
    "executionInfo": {
     "elapsed": 834,
     "status": "ok",
     "timestamp": 1754554549519,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "SkAm8dwcVsxK",
    "outputId": "20628ecd-4935-4a89-cdec-da3bf2fbfc3d"
   },
   "outputs": [],
   "source": [
    "df = data_df.copy()\n",
    "df['label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NjV5W8YQVsxL"
   },
   "source": [
    "# 🔨 Utility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 873,
     "status": "ok",
     "timestamp": 1754554550394,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "cewt5LwyVsxL"
   },
   "outputs": [],
   "source": [
    "def load_img(image_path, mask_path, scale = True):\n",
    "    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.resize(img, (CFG.img_size[1], CFG.img_size[0]), interpolation=cv2.INTER_LINEAR)\n",
    "    if mask_path == \"\":\n",
    "        mask = np.zeros_like(img, dtype=np.uint8)\n",
    "    else:\n",
    "        mask = cv2.imread(mask_path, cv2.IMREAD_GRAYSCALE)\n",
    "        mask = cv2.resize(mask, (CFG.img_size[1], CFG.img_size[0]), interpolation=cv2.INTER_LINEAR)\n",
    "        mask = (mask > 0).astype(np.uint8)\n",
    "\n",
    "    img = np.expand_dims(img.astype(\"float32\"), axis=-1)\n",
    "    mask = np.expand_dims(mask.astype(\"float32\"), axis=-1)\n",
    "    if scale:\n",
    "        img = (img - img.min()) / (img.max() - img.min())\n",
    "        # img = (img - img.mean()) / img.std()\n",
    "    assert img.shape == mask.shape, f\"Image shape {img.shape} does not match mask shape {mask.shape}\"\n",
    "    return img, mask\n",
    "\n",
    "\n",
    "def get_dice(preds, masks, threshold=0.5, epsilon=1e-6):\n",
    "    \"\"\"\n",
    "    Compute per-image Dice coefficient and return the mean across the batch.\n",
    "\n",
    "    preds, masks: np.ndarray of shape (B, H, W) or (B, 1, H, W)\n",
    "    \"\"\"\n",
    "    preds = (preds > threshold).astype(np.uint8)\n",
    "    masks = (masks > threshold).astype(np.uint8)\n",
    "\n",
    "    if preds.ndim == 4 and preds.shape[1] == 1:\n",
    "        preds = preds[:, 0]\n",
    "        masks = masks[:, 0]\n",
    "\n",
    "    intersection = (preds & masks).sum(axis=(1, 2))\n",
    "    total = preds.sum(axis=(1, 2)) + masks.sum(axis=(1, 2))\n",
    "\n",
    "    dice_scores = (2.0 * intersection + epsilon) / (total + epsilon)\n",
    "    return dice_scores.mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9ZmvxbnlVsxM"
   },
   "source": [
    "# 📁 Create Folds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "executionInfo": {
     "elapsed": 1020,
     "status": "ok",
     "timestamp": 1754554551415,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "1SHeAiTmVsxM",
    "outputId": "57ee156c-7ed4-44ac-bc14-551b3b6f4ef4"
   },
   "outputs": [],
   "source": [
    "skf = StratifiedGroupKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\n",
    "for fold,(train_idx, val_idx) in enumerate(skf.split(df, df['label'], df['image_id'])):\n",
    "    df.loc[val_idx, 'fold'] = fold\n",
    "display(df.groupby(['fold','label'])['image_id'].count())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4ClsjaTeVsxM"
   },
   "source": [
    "# 🍚 Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 992,
     "status": "ok",
     "timestamp": 1754554552410,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "-Qm7X0VtVsxM"
   },
   "outputs": [],
   "source": [
    "class BuildDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self,\n",
    "                 df,\n",
    "                 transforms=None):\n",
    "\n",
    "        self.df           = df.reset_index(drop=True)\n",
    "        self.transforms   = transforms\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        img_path = self.df.image_path[index]\n",
    "        label_path = self.df.label_path[index]\n",
    "\n",
    "        ## Load the image (RGB)\n",
    "        img, mask = load_img(img_path, label_path, True)\n",
    "        ## Apply Augmentations:\n",
    "        if self.transforms:\n",
    "            data = self.transforms(image=img, mask=mask)\n",
    "            img  = data['image']\n",
    "            mask = data['mask']\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "        else:\n",
    "            img = np.transpose(img, (2, 0, 1))\n",
    "\n",
    "        mask = np.transpose(mask, (2, 0, 1))\n",
    "\n",
    "        # if CFG.aux_head and self.label:\n",
    "        #     labels = np.where(mask.sum((1, 2)) > 0, 1, 0)\n",
    "        # else:\n",
    "        #     labels = mask\n",
    "        img = torch.tensor(img)\n",
    "        mask = torch.tensor(mask)\n",
    "        return torch.tensor(img), torch.tensor(mask), img_path\n",
    "\n",
    "\n",
    "class TTADataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, base_dataset, tta_transforms):\n",
    "        self.base_dataset = base_dataset\n",
    "        self.tta_transforms = tta_transforms\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.base_dataset)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image, mask, img_path = self.base_dataset[idx]\n",
    "\n",
    "        image = image.permute(1, 2, 0).numpy()\n",
    "\n",
    "        all_aug_images = []\n",
    "        for t in self.tta_transforms:\n",
    "            aug = t(image=image)['image']\n",
    "            aug = torch.from_numpy(aug).permute(2, 0, 1).float()  # back to CHW\n",
    "            all_aug_images.append(aug)\n",
    "\n",
    "        return torch.stack(all_aug_images), mask, img_path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XgW-COnNVsxM"
   },
   "source": [
    "# Augmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 942,
     "status": "ok",
     "timestamp": 1754554553357,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "hJmOZ14VVsxN"
   },
   "outputs": [],
   "source": [
    "data_transforms = {\"train\": A.Compose([A.HorizontalFlip(p=0.5),\n",
    "                                       A.VerticalFlip(p=0.5),\n",
    "                                       A.RandomBrightnessContrast(brightness_limit=[-0.5, 0.5],contrast_limit=[0,0],p=0.5),\n",
    "                                       A.GaussianBlur(sigma_limit=[0.1, 0.8],p=0.5),\n",
    "                                       A.GaussNoise(std_range=[0.01,0.3],per_channel=False,noise_scale_factor=0.7,p=0.5),\n",
    "                                       A.SaltAndPepper(p=0.5),\n",
    "                                    #    A.ShiftScaleRotate(rotate_limit=25, scale_limit=0.15, shift_limit=0, p=0.25),\n",
    "#                                        A.CoarseDropout(max_holes=16, max_height=64 ,max_width=64 ,p=0.5),\n",
    "#                                        A.ColorJitter(brightness=0.25, contrast=0.25, saturation=0.25, hue=0.25, p=0.75),\n",
    "#                                        A.GridDistortion(num_steps=5, distort_limit=0.3, interpolation=1, p=0.5),\n",
    "                                       # A.RandomCrop(height=CFG.img_size[0], width=CFG.img_size[1], always_apply=True, p=1),\n",
    "                                       # A.Normalize(p=1)\n",
    "                                        ]),\n",
    "\n",
    "                    \"valid\": A.Compose([]),#PadToDivisible(divisible=32, always_apply=True, p=1.0),\n",
    "\n",
    "                    \"tta\": [\n",
    "                        A.Compose([]),  # identity\n",
    "                        A.HorizontalFlip(p=1.0),\n",
    "                        A.VerticalFlip(p=1.0)\n",
    "                     ]\n",
    "                    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wU2Oq3dcVsxN"
   },
   "source": [
    "# DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1015,
     "status": "ok",
     "timestamp": 1754554554376,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "T16Zv7DgVsxN"
   },
   "outputs": [],
   "source": [
    "def prepare_loaders(fold, non_empty=False):\n",
    "    train_df = df[df.fold != fold].reset_index(drop=True)\n",
    "    valid_df = df[df.fold == fold].reset_index(drop=True)\n",
    "\n",
    "    if non_empty:\n",
    "        train_df = train_df[train_df['label'] == 0].reset_index(drop=True)\n",
    "        valid_df = valid_df[valid_df['label'] == 0].reset_index(drop=True)\n",
    "\n",
    "    train_dataset = BuildDataset(train_df, transforms=data_transforms['train'])\n",
    "    valid_dataset = BuildDataset(valid_df, transforms=data_transforms['valid'])\n",
    "\n",
    "    # Wrap the validation dataset in a deterministic TTA wrapper\n",
    "    base_oof_dataset = BuildDataset(valid_df, transforms=data_transforms['valid'])\n",
    "    oof_dataset = TTADataset(base_oof_dataset, tta_transforms=data_transforms['tta'])\n",
    "\n",
    "    train_loader = DataLoader(train_dataset, batch_size=CFG.train_bs,\n",
    "                              num_workers=8, shuffle=True, pin_memory=True, drop_last=False)\n",
    "\n",
    "    valid_loader = DataLoader(valid_dataset, batch_size=1,\n",
    "                              num_workers=8, shuffle=False, pin_memory=True)\n",
    "\n",
    "    oof_loader = DataLoader(oof_dataset, batch_size=1,  # returns [1, T, C, H, W]\n",
    "                            num_workers=8, shuffle=False, pin_memory=True)\n",
    "\n",
    "    return train_loader, valid_loader, oof_loader, len(train_df) // CFG.train_bs, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 858,
     "status": "ok",
     "timestamp": 1754554555230,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "C57lafU6VsxN"
   },
   "outputs": [],
   "source": [
    "train_loader, valid_loader, oof_loader, training_steps, valid_df = prepare_loaders(fold=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2263,
     "status": "ok",
     "timestamp": 1754554557495,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "bduG69MdVsxN"
   },
   "outputs": [],
   "source": [
    "imgs, masks, path_ = next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 4496,
     "status": "ok",
     "timestamp": 1754554561998,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "d8UTNBg0VsxO",
    "outputId": "f69433ea-628a-43df-f0fe-e105f00c0cc7"
   },
   "outputs": [],
   "source": [
    "for i in range(imgs.shape[0]):\n",
    "    #make the image and mask two suplots horizontally with third image overlaying them together\n",
    "    _img = np.transpose(imgs[i].cpu().numpy(), (1, 2, 0))\n",
    "    mask = np.transpose(masks[i].cpu().numpy(), (1, 2, 0))\n",
    "    fig, ax = plt.subplots(1,3, figsize=(12, 6))\n",
    "    ax[0].imshow(_img)\n",
    "    ax[0].set_title(\"Image\")\n",
    "    ax[1].imshow(mask, alpha = 0.25)\n",
    "    ax[1].set_title(\"Mask\")\n",
    "    ax[2].imshow(_img)\n",
    "    ax[2].imshow(mask, alpha = 0.25)\n",
    "    ax[2].set_title(\"Overlay\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5168,
     "status": "ok",
     "timestamp": 1754554567172,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "EESuNa8rVsxO"
   },
   "outputs": [],
   "source": [
    "imgs, msks, paths_ = next(iter(valid_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 471
    },
    "executionInfo": {
     "elapsed": 5460,
     "status": "ok",
     "timestamp": 1754554572634,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "1RV54dd9VsxO",
    "outputId": "3d2f5823-d63c-44c8-e9b8-9121fffb38af"
   },
   "outputs": [],
   "source": [
    "for i in range(imgs.shape[0]):\n",
    "    _img = np.transpose(imgs[i].cpu().numpy(), (1, 2, 0))\n",
    "    _mask = np.transpose(msks[i].cpu().numpy(), (1, 2, 0))\n",
    "    print(_img.max(), _img.min())\n",
    "    print(np.unique(_mask))\n",
    "    plt.imshow(_img)\n",
    "    plt.imshow(_mask, alpha = 0.25, cmap = 'gray')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5261,
     "status": "ok",
     "timestamp": 1754554577898,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "o_UkgS52VsxO",
    "outputId": "730e6790-1cd0-49fd-86f4-47e572e8eb1c"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6CgrPFhhVsxO"
   },
   "source": [
    "# 📦 Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5014,
     "status": "ok",
     "timestamp": 1754554582914,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "pvnuvoDoVsxP"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def build_model():\n",
    "    model = smp.Unet(encoder_name=CFG.backbone,      # choose encoder, e.g. mobilenet_v2 or efficientnet-b7\n",
    "                     encoder_weights=\"imagenet\",     # use `imagenet` pre-trained weights for encoder initialization\n",
    "                     in_channels=1,                  # model input channels (1 for gray-scale images, 3 for RGB, etc.)\n",
    "                     classes=1,                      # model output channels (number of classes in your dataset)\n",
    "                     activation=None,\n",
    "                     decoder_attention_type = CFG.decoder_attention_type, #\"scse\",\n",
    "                     aux_params = None if not CFG.aux_head else {\"classes\": 1,\n",
    "                                                                 \"activation\": None})\n",
    "    model.to(CFG.device)\n",
    "    return model\n",
    "\n",
    "\n",
    "def load_model(path):\n",
    "    model = build_model()\n",
    "    model.load_state_dict(torch.load(path))\n",
    "    model.eval()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b_Tj8sMrVsxP"
   },
   "source": [
    "# 🔧 Loss Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5064,
     "status": "ok",
     "timestamp": 1754554587980,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "7rdN805oVsxP"
   },
   "outputs": [],
   "source": [
    "JaccardLoss    = smp.losses.JaccardLoss(mode='binary')\n",
    "DiceLoss       = smp.losses.DiceLoss(mode='binary')\n",
    "BCELoss        = smp.losses.SoftBCEWithLogitsLoss()\n",
    "LovaszLoss     = smp.losses.LovaszLoss(mode='binary', per_image=False)\n",
    "TverskyLoss    = smp.losses.TverskyLoss(mode='binary', log_loss=False, smooth=0.1)\n",
    "SegFocalLoss   = smp.losses.FocalLoss(mode = 'binary')\n",
    "BCE = torch.nn.BCEWithLogitsLoss()\n",
    "\n",
    "def dice_coef(y_true, y_pred, thr=0.5, dim=(2, 3), epsilon=1e-6):\n",
    "    y_true = y_true.float()\n",
    "    y_pred = (y_pred > thr).float()\n",
    "    inter = (y_true * y_pred).sum(dim=dim)\n",
    "    den = y_true.sum(dim=dim) + y_pred.sum(dim=dim)\n",
    "    dice = (2 * inter + epsilon) / (den + epsilon)\n",
    "    return dice.mean()  # mean over batch (and channel if present)\n",
    "\n",
    "\n",
    "def iou_coef(y_true, y_pred, thr=0.5, dim=(2, 3), epsilon=1e-6):\n",
    "    y_true = y_true.float()\n",
    "    y_pred = (y_pred > thr).float()\n",
    "    inter = (y_true * y_pred).sum(dim=dim)\n",
    "    union = y_true.sum(dim=dim) + y_pred.sum(dim=dim) - inter\n",
    "    iou = (inter + epsilon) / (union + epsilon)\n",
    "    return iou.mean()  # mean over batch\n",
    "\n",
    "\n",
    "def criterion(y_pred, y_true):\n",
    "    return DiceLoss(y_pred, y_true)\n",
    "\n",
    "# def criterion(y_pred, y_true):\n",
    "#     if CFG.aux_head:\n",
    "#         y_true, yt_class = y_true\n",
    "#         y_pred, yp_class = y_pred\n",
    "#         return (0.5*DiceLoss(y_pred, y_true) + 0.5 * BCE(yp_class, yt_class))\n",
    "#     return 0.5*DiceLoss(y_pred, y_true) + 0.5*SegFocalLoss(y_pred, y_true)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "KNH4IcA9VsxP"
   },
   "source": [
    "# 🚄 Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 4538,
     "status": "ok",
     "timestamp": 1754554592522,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "9VjbX-crVsxP"
   },
   "outputs": [],
   "source": [
    "def train_one_epoch(model, optimizer, scheduler, dataloader, device, epoch:int):\n",
    "    model.train()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    train_jaccards = []\n",
    "    train_dices = []\n",
    "\n",
    "    sigmoid = torch.sigmoid  # Faster than instantiating nn.Sigmoid()\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Train ')\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    for step, (images, masks, paths) in pbar:\n",
    "        images = images.to(device, dtype=torch.float)\n",
    "        masks  = masks.to(device, dtype=torch.float)\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, masks)\n",
    "        loss.backward()\n",
    "\n",
    "        y_pred = sigmoid(y_pred)\n",
    "\n",
    "        train_dice = dice_coef(masks, y_pred).cpu().item()\n",
    "        train_jaccard = iou_coef(masks, y_pred).cpu().item()\n",
    "        train_dices.append(train_dice)\n",
    "        train_jaccards.append(train_jaccard)\n",
    "\n",
    "        if (step + 1) % CFG.n_accumulate == 0:\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if scheduler and CFG.scheduler not in [\"ReduceLROnPlateau\", \"ExponentialLR\"]:\n",
    "                scheduler.step()\n",
    "\n",
    "        running_loss += loss.item() * batch_size\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "        wandb.log({'train_loss': running_loss, 'epoch': epoch})\n",
    "        # W&B per-epoch training metrics\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        mem = torch.cuda.memory_reserved() / 1e9 if torch.cuda.is_available() else 0\n",
    "\n",
    "        pbar.set_postfix(loss=f'{epoch_loss:0.4f}',\n",
    "                         lr=f'{current_lr:0.5f}',\n",
    "                         jac=np.mean(train_jaccards),\n",
    "                         dice=np.mean(train_dices),\n",
    "                         gpu_mem=f'{mem:0.2f} GB')\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss, np.mean(train_dices), np.mean(train_jaccards)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "p5xfLa1dVsxP"
   },
   "source": [
    "# 👀 Validation Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3111,
     "status": "ok",
     "timestamp": 1754554595639,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "bWJIWkr8VsxQ"
   },
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def valid_one_epoch(model, dataloader, device, optimizer, epoch:int):\n",
    "    model.eval()\n",
    "\n",
    "    dataset_size = 0\n",
    "    running_loss = 0.0\n",
    "    global_masks = []\n",
    "    global_preds = []\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='Valid ')\n",
    "\n",
    "    for step, (images, masks, paths) in pbar:\n",
    "        images = images.float().to(device)\n",
    "        masks = masks.float().to(device)\n",
    "        batch_size = images.size(0)\n",
    "\n",
    "        y_pred = model(images)\n",
    "        loss = criterion(y_pred, masks)\n",
    "        running_loss += loss.item() * batch_size\n",
    "        dataset_size += batch_size\n",
    "\n",
    "        epoch_loss = running_loss / dataset_size\n",
    "\n",
    "        y_pred = torch.sigmoid(y_pred)\n",
    "        global_masks.append(masks.cpu().numpy())\n",
    "        global_preds.append(y_pred.detach().cpu().numpy())\n",
    "\n",
    "        current_lr = optimizer.param_groups[0]['lr']\n",
    "        mem = torch.cuda.memory_reserved() / 1E9 if torch.cuda.is_available() else 0\n",
    "        pbar.set_postfix(valid_loss=f'{epoch_loss:0.4f}',\n",
    "                         lr=f'{current_lr:0.5f}',\n",
    "                         gpu_mem=f'{mem:0.2f} GB')\n",
    "\n",
    "    # For sample images, take first example of last batch\n",
    "    # Concatenate all batches\n",
    "    global_masks = np.concatenate(global_masks, axis=0)\n",
    "    global_preds = np.concatenate(global_preds, axis=0)\n",
    "    global_dice = get_dice(global_preds, global_masks)\n",
    "\n",
    "    # Log overall validation metrics\n",
    "    wandb.log({'val_loss': epoch_loss, 'val_dice': global_dice, 'epoch': epoch})\n",
    "\n",
    "    # For sample images, take first example of last batch\n",
    "    img_np = images[0].cpu().permute(1,2,0).numpy()\n",
    "    mask_np = masks[0].cpu().permute(1,2,0).numpy()\n",
    "    pred_np = global_preds[-1][0].astype('float32') # Remove transpose as it's a single channel\n",
    "    wandb.log({\n",
    "        'input': wandb.Image(img_np, caption='input'),\n",
    "        'mask': wandb.Image(mask_np, caption='mask'),\n",
    "        'pred': wandb.Image(pred_np, caption='pred'),\n",
    "        'epoch': epoch\n",
    "    })\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return epoch_loss, global_dice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3083,
     "status": "ok",
     "timestamp": 1754554598724,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "OehpCF8AVsxQ"
   },
   "outputs": [],
   "source": [
    "def reverse_transform(pred, transform_type):\n",
    "    if transform_type == \"hflip\":\n",
    "        return np.fliplr(pred)\n",
    "    elif transform_type == \"vflip\":\n",
    "        return np.flipud(pred)\n",
    "    elif transform_type == \"identity\":\n",
    "        return pred\n",
    "    else:\n",
    "        raise ValueError(f\"Unknown TTA transform: {transform_type}\")\n",
    "\n",
    "@torch.no_grad()\n",
    "def oof_one_epoch(model, dataloader, device, valid_df, fold, tta_transform_names):\n",
    "    model.eval()\n",
    "\n",
    "    oof_scores = []\n",
    "    global_preds = []\n",
    "    global_masks = []\n",
    "\n",
    "    pbar = tqdm(enumerate(dataloader), total=len(dataloader), desc='OOF Eval')\n",
    "\n",
    "    for step, (tta_images, masks, img_path) in pbar:\n",
    "        tta_images = tta_images.squeeze(0).to(device).float()\n",
    "        masks = masks.squeeze(0).to(device).float()\n",
    "        img_path = img_path[0] if isinstance(img_path, list) else img_path\n",
    "        img_path = str(img_path)  # ensure string for merging\n",
    "\n",
    "        preds = model(tta_images)\n",
    "        preds = torch.sigmoid(preds).squeeze(1).cpu().numpy()\n",
    "        masks_np = masks.squeeze().cpu().numpy()\n",
    "\n",
    "        aligned_preds = []\n",
    "        for pred, tname in zip(preds, tta_transform_names):\n",
    "            aligned_preds.append(reverse_transform(pred, tname))\n",
    "\n",
    "        aligned_preds = np.stack(aligned_preds, axis=0)\n",
    "        tta_avg_pred = aligned_preds.mean(axis=0)\n",
    "        base_pred = aligned_preds[0]\n",
    "\n",
    "        base_dice = get_dice(base_pred[None], masks_np[None])\n",
    "        tta_dice = get_dice(tta_avg_pred[None], masks_np[None])\n",
    "\n",
    "        global_preds.append(tta_avg_pred[None])\n",
    "        global_masks.append(masks_np[None])\n",
    "\n",
    "        oof_scores.append({\n",
    "            'image_path': img_path,\n",
    "            'base_dice': base_dice,\n",
    "            'tta_dice': tta_dice\n",
    "        })\n",
    "\n",
    "        pbar.set_postfix(base_dice=f'{base_dice:.4f}', tta_dice=f'{tta_dice:.4f}')\n",
    "\n",
    "    df_scores = pd.DataFrame(oof_scores)\n",
    "\n",
    "    # Merge on image_path instead of index\n",
    "    valid_df = valid_df.copy()\n",
    "    valid_df = valid_df.merge(df_scores, on='image_path', how='left')\n",
    "    valid_df.to_csv(f'tta_results_fold_{fold}.csv', index=False)\n",
    "\n",
    "    global_preds = np.concatenate(global_preds, axis=0)\n",
    "    global_masks = np.concatenate(global_masks, axis=0)\n",
    "    global_dice = get_dice(global_preds, global_masks)\n",
    "\n",
    "    torch.cuda.empty_cache()\n",
    "    gc.collect()\n",
    "\n",
    "    return global_dice, valid_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I8kBDjqwVsxQ"
   },
   "source": [
    "# 🏃 Run Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3442,
     "status": "ok",
     "timestamp": 1754554602168,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "hD-hLEM_VsxQ"
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "import time\n",
    "import copy\n",
    "import torch\n",
    "import gc\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "def run_training(model, optimizer, scheduler, num_epochs, train_loader, valid_loader, fold=0):\n",
    "    if torch.cuda.is_available():\n",
    "        print(f\"CUDA: {torch.cuda.get_device_name()}\\n\")\n",
    "\n",
    "    # Create the 'models' directory if it doesn't exist\n",
    "    os.makedirs('models', exist_ok=True)\n",
    "\n",
    "    wandb.watch(model, log='all', log_freq=10)\n",
    "\n",
    "    start_time = time.time()\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_dice = -np.inf\n",
    "    best_epoch = -1\n",
    "    history = defaultdict(list)\n",
    "\n",
    "    for epoch in range(1, num_epochs + 1):\n",
    "        gc.collect()\n",
    "        print(f\"{'='*30}\\nEpoch {epoch}/{num_epochs}\")\n",
    "\n",
    "        train_loss, train_dice, train_jaccard = train_one_epoch(\n",
    "            model=model,\n",
    "            optimizer=optimizer,\n",
    "            scheduler=scheduler,\n",
    "            dataloader=train_loader,\n",
    "            device=CFG.device,\n",
    "            epoch=epoch,\n",
    "        )\n",
    "\n",
    "        val_loss, val_dice = valid_one_epoch(\n",
    "            model=model,\n",
    "            dataloader=valid_loader,\n",
    "            device=CFG.device,\n",
    "            optimizer=optimizer,\n",
    "            epoch=epoch\n",
    "        )\n",
    "\n",
    "        history['Train Loss'].append(train_loss)\n",
    "        history['Valid Loss'].append(val_loss)\n",
    "        history['Valid Dice'].append(val_dice)\n",
    "\n",
    "        print(f\"Train Loss: {train_loss:.4f} - Train Dice: {train_dice:.4f} - Train Jaccard: {train_jaccard:.4f} | Valid Loss: {val_loss:.4f} | Valid Dice: {val_dice:.4f}\")\n",
    "\n",
    "        # Save best model\n",
    "        if val_dice > best_dice:\n",
    "            print(f\"✓ Dice Improved: {best_dice:.4f} → {val_dice:.4f}\")\n",
    "            best_dice = val_dice\n",
    "            best_epoch = epoch\n",
    "            best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "            best_path = f'models/best_fold{fold}_dice{best_dice:.4f}.pth'\n",
    "            torch.save(model.state_dict(), best_path)\n",
    "            print(f\"✔ Model saved to {best_path}\")\n",
    "            # W&B artifact\n",
    "            artifact = wandb.Artifact(f'best_model_fold{fold}', type='model')\n",
    "            artifact.add_file(best_path)\n",
    "            run.log_artifact(artifact)\n",
    "\n",
    "        # Always save last epoch\n",
    "        last_path = f\"last_epoch-S1-{fold:02d}.bin\"\n",
    "        torch.save(model.state_dict(), last_path)\n",
    "\n",
    "        # Step scheduler if applicable\n",
    "        if CFG.scheduler in [\"ReduceLROnPlateau\", \"ExponentialLR\"]:\n",
    "            if CFG.scheduler == \"ExponentialLR\":\n",
    "                scheduler.step()\n",
    "            elif CFG.scheduler == \"ReduceLROnPlateau\":\n",
    "                scheduler.step(val_loss)\n",
    "\n",
    "        print()\n",
    "\n",
    "    elapsed = time.time() - start_time\n",
    "    h, m, s = int(elapsed // 3600), int((elapsed % 3600) // 60), int(elapsed % 60)\n",
    "    print(f\"🏁 Training complete in {h}h {m}m {s}s\")\n",
    "    print(f\"🏆 Best Dice: {best_dice:.4f} (Epoch {best_epoch})\")\n",
    "\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model, history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5026,
     "status": "ok",
     "timestamp": 1754554607195,
     "user": {
      "displayName": "Maia Austigard",
      "userId": "14869657233601930507"
     },
     "user_tz": -120
    },
    "id": "84sNBfK8VsxQ"
   },
   "outputs": [],
   "source": [
    "\n",
    "def fetch_scheduler(optimizer: Optimizer, training_steps: int = 0):\n",
    "    match CFG.scheduler:\n",
    "        case \"CosineAnnealingLR\":\n",
    "            scheduler = lr_scheduler.CosineAnnealingLR(\n",
    "                optimizer, T_max=training_steps * CFG.epochs, eta_min=CFG.min_lr\n",
    "            )\n",
    "        case \"CosineAnnealingWarmRestarts\":\n",
    "            scheduler = lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                optimizer, T_0=training_steps * 8, T_mult=1, eta_min=CFG.min_lr\n",
    "            )\n",
    "        case \"ReduceLROnPlateau\":\n",
    "            scheduler = lr_scheduler.ReduceLROnPlateau(\n",
    "                optimizer,\n",
    "                mode=\"max\",\n",
    "                factor=0.5,\n",
    "                patience=1,\n",
    "                cooldown=1,\n",
    "                min_lr=5e-6,\n",
    "                threshold=0.00001,\n",
    "            )\n",
    "        case \"OneCycle\":\n",
    "            scheduler = lr_scheduler.OneCycleLR(\n",
    "                optimizer,\n",
    "                max_lr=CFG.max_lr,\n",
    "                total_steps=training_steps * CFG.epochs,\n",
    "                # epochs=CFG.epochs,\n",
    "                # steps_per_epoch=training_steps,\n",
    "                pct_start=0.25,\n",
    "            )\n",
    "        case \"ExponentialLR\":\n",
    "            scheduler = lr_scheduler.ExponentialLR(optimizer, gamma=0.9)\n",
    "        case _:\n",
    "            print(\n",
    "                f\"{c_}⚠️ WARNING: Unknown scheduler {CFG.scheduler}. Using StepLR with step_size=1.{sr_}\"\n",
    "            )\n",
    "            return None\n",
    "\n",
    "    return scheduler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YQK7aCZuVsxR"
   },
   "source": [
    "# 🚅 Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "wCTrrBqyVsxR",
    "outputId": "036c4bee-ccbc-4f79-e5c4-4fbc92ce88e4"
   },
   "outputs": [],
   "source": [
    "oof_dice_scores = []\n",
    "all_oof_dfs = []\n",
    "tta_transform_names = [\"identity\", \"hflip\", \"vflip\"]\n",
    "\n",
    "for fold in CFG.folds:\n",
    "    print(f'\\n{\"#\"*30}\\n##### Fold {fold}\\n{\"#\"*30}\\n')\n",
    "    run.name = f\"fold{fold}_{datetime.now():%Y%m%d_%H%M%S}\"\n",
    "    model = build_model()\n",
    "\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=CFG.lr, weight_decay=0.05)\n",
    "    CFG.scheduler = \"CosineAnnealingLR\"\n",
    "\n",
    "    # Loaders for this fold (train + valid + TTA OOF)\n",
    "    train_loader, valid_loader, oof_loader, train_steps, valid_df = prepare_loaders(\n",
    "        fold=fold,\n",
    "        non_empty=False,\n",
    "    )\n",
    "\n",
    "    scheduler = fetch_scheduler(optimizer, train_steps)\n",
    "\n",
    "    # Train model\n",
    "    model, _ = run_training(\n",
    "        model=model,\n",
    "        optimizer=optimizer,\n",
    "        scheduler=scheduler,\n",
    "        num_epochs=CFG.epochs,\n",
    "        train_loader=train_loader,\n",
    "        valid_loader=valid_loader,\n",
    "        fold=fold\n",
    "    )\n",
    "\n",
    "    # TTA-based OOF prediction\n",
    "    oof_dice, valid_df_with_scores = oof_one_epoch(\n",
    "        model=model,\n",
    "        dataloader=oof_loader,\n",
    "        device=CFG.device,\n",
    "        valid_df=valid_df,\n",
    "        fold=fold,\n",
    "        tta_transform_names=tta_transform_names\n",
    "    )\n",
    "\n",
    "    print(f\"✅ Fold {fold} OOF Dice: {oof_dice:.4f}\")\n",
    "\n",
    "    oof_dice_scores.append(oof_dice)\n",
    "    all_oof_dfs.append(valid_df_with_scores)\n",
    "\n",
    "# Final average OOF Dice\n",
    "mean_oof_dice = np.mean(oof_dice_scores)\n",
    "print(f\"\\n{'='*40}\\n🏁 Final OOF Dice across all folds: {mean_oof_dice:.4f}\")\n",
    "\n",
    "# Save full OOF dataframe\n",
    "final_oof_df = pd.concat(all_oof_dfs, ignore_index=True)\n",
    "final_oof_df.to_csv(\"oof_scores_all_folds.csv\", index=False)\n",
    "\n",
    "# Finish W&B\n",
    "run.finish()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oLS_oYyqVsxR"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "A100",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
