# RAG Configuration
# Embedding model runs locally on Ollama
EMBEDDINGS_BASE_URL=http://localhost:11434
EMBEDDINGS_MODEL=mxbai-embed-large

# LLM runs on cloud RunPod instance
LLM_BASE_URL=https://11n4k38q0zmgv4-11434.proxy.runpod.net
LLM_MODEL=cogito:32b

# Vector database configuration
CHROMA_PATH=chroma
CHUNK_SIZE=800
CHUNK_OVERLAP=80

# API configuration
API_HOST=0.0.0.0
API_PORT=8000
