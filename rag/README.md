# Emergency Healthcare RAG

![Kiku](../images/emergency-rag-banner.png)

In this use case, your job is to help an emergency department answer critical medical questions fast and accurately!

You will receive medical statements about emergency healthcare conditions that need to be evaluated for truth and classified by topic. Each statement must be processed in two ways:

- **Binary classification**: Determine if the statement is true or false
- **Multi-class classification**: Identify which medical topic the statement concerns

The dataset (`data/`) comprises medical statements generated by Claude Opus based on reference articles covering 115 emergency healthcare topics (`data/topics/`). Your predictions will be scored by accuracy for both the binary classification (true/false) and multi-class classification (topic identification):

$$
Accuracy = \\frac{\\text{Number of correct predictions}}{\\text{Total number of predictions}}
$$

The training set, validation set and evaluation set contain 200, 200 and 749 statements respectively. All statements are generated based on the medical reference material found in `data/topics/`. The medical topics range from emergency conditions like stroke, cardiac arrest, and trauma to diagnostic procedures like CT scans, blood tests, and ECGs. The complete topic mapping is provided in `data/topics.json`.

### Example Statement

**Statement**: "Cancer patients with pulmonary embolism have the highest VTE recurrence risk with pancreatic cancer, hematological malignancies, lung cancer, gastric cancer, and brain cancer carrying the greatest thrombotic risk, necessitating extended anticoagulation with LMWH or direct oral anticoagulants preferred over vitamin K antagonists."

**Expected Output**:

```json
{
  "statement_is_true": 1,
  "statement_topic": 63
}
```

*Topic 63 corresponds to "Pulmonary Embolism" in the topic mapping.*

## Constraints

Since this is an emergency department scenario, your solution must operate under strict constraints:

- **Speed**: Maximum 5 seconds per statement evaluation
- **Privacy**: Must run completely offline - no cloud API calls during inference
- **Memory**: Maximum 24GB VRAM usage at any time during inference

## Evaluation

During the week of the competition, you will be able to validate your solution against the validation set. You can do this multiple times, however, **you can only submit to the evaluation set once!** The best validation and evaluation score your model achieves will be displayed on the <a href="https://cases.dmiai.dk/teams"> scoreboard</a>. We encourage you to validate your code and API before you submit your final model to evaluation.

## Setup Summary

### System Overview

This Emergency Healthcare RAG system uses:

- **BM25s retrieval** with enhanced indexing including training data
- **Mistral 7B-Instruct** via Ollama for fast, clean JSON outputs
- **115 medical topics** covering emergency conditions and diagnostic procedures
- **Optimized context selection** for improved topic classification accuracy
- **Response times ~8-10 seconds** meeting performance constraints

### Key Features

- ✅ **Enhanced BM25s indexing** with training data for better context retrieval
- ✅ **Topic diversity** - No longer stuck on single topics, proper adaptation
- ✅ **Binary classification** with improved accuracy for true/false statements
- ✅ **Context optimization** - Limited to top 5 contexts (200 chars each) for speed
- ✅ **Cache system** - BM25s index cached for fast startup
- ✅ **Offline operation** - No cloud API dependencies

### Performance Metrics (Latest Evaluation)

- **Context Recall:** 100%
- **Context Precision:** 91.34%
- **Binary Accuracy:** 50%
- **Topic Accuracy:** 40%
- **Response Time:** ~8.8 seconds
- **Overall Accuracy:** 20%

## Quickstart

Navigate to the Emergency Healthcare RAG directory:

```bash
cd src/rag
```

Install dependencies:

```bash
uv sync
```

**Setup Ollama and Mistral model:**

```bash
# Start Ollama server
ollama serve

# Pull Mistral 7B-Instruct model
ollama pull mistral:7b-instruct
```

Make a local prediction using the enhanced RAG model:

```bash
uv run python example.py
```

**Run full evaluation:**

```bash
uv run python rag-evaluation/src/evaluation/main.py
```

## Validation

Submit your solution for validation:

```bash
# Submit for validation
uv run validate

# Check validation status
uv run check-status <uuid>

# Submit and wait for completion
uv run validate --wait
```

## API Testing

The unified API serves all tasks with auto port cleanup and hot reload:

```bash
cd ../shared
uv sync       # Install all API dependencies
uv run api    # Start API with auto port cleanup
```

**Features:**

- ✅ **Auto port cleanup** - Kills any existing process on port 8000
- ✅ **Hot reload** - Automatically restarts when code changes
- ✅ **All dependencies** - Includes FastAPI, NumPy, Loguru, and more

Test the healthcare endpoint at `http://localhost:8000/predict`:

```bash
curl -X POST http://localhost:8000/predict \
     -H "Content-Type: application/json" \
     -d '{"statement": "Aspirin can help reduce fever and pain."}'
```

**Expected Response:**

```json
{"statement_is_true": 1, "statement_topic": 0}
```

## Validation Using Pinggy Tunnel

To properly validate your local Healthcare BM25s RAG server against the Norwegian AI Championship competition server, follow these steps:

### 1. Run the Server Locally

From your project root (e.g., `rag` folder), start the RAG API server:

```bash
uv run api
```

This will start the server locally at `http://localhost:8000`.

### 1.5. Monitor Server Logs

To follow the server logs in real-time:

```bash
tail -f logs/api.log
```

### 2. Open a New Terminal

In a separate terminal window, navigate to the project directory where you want to run validation commands.

### 3. Create a Pinggy Tunnel

Use SSH to expose your local port 8000 to the internet via Pinggy:

```bash
ssh -p 443 -R0:localhost:8000 free.pinggy.io
```

Replace `8000` with the port your service is listening on if different.

- The tunnel will allocate a public HTTPS URL forwarding to your local service.
- Keep this terminal open as long as the tunnel should remain active.

### 4. Use the Pinggy URL For Validation

Go to the Norwegian AI Championship website: [https://cases.ainm.no/](https://cases.ainm.no/)

- Navigate to the task you are working on (e.g., Emergency Healthcare RAG).
- Paste your Pinggy HTTPS URL (e.g., `https://rnxtd-....a.free.pinggy.link/predict`) as the endpoint URL.
- Enter your competition token.
- Submit the evaluation request.

### 5. Monitor Validation Results

- The remote competition server will send test queries to your exposed endpoint.
- You can monitor logs locally and check the scoreboard.

**Benefits of this method:**

- Your server runs locally with all optimizations.
- The competition server accesses your system reliably via HTTPS.
- You avoid issues with local-only or cached API instances.
- Validation runs smoothly and reflects your optimized model performance.

## About the data

The medical statements have been generated by Claude Opus based on StatPearls medical reference articles (`data/topics`). Medical topics include emergency conditions such as stroke, myocardial infarction, respiratory failure, and trauma, as well as diagnostic procedures like ECG interpretation, blood gas analysis, and medical imaging. The complete list of 115 topics is available in `data/topics.json`.

## Tips & Getting Started

**Retrieval-Augmented Generation (RAG)** can be used with the reference articles in `data/topics/`.
[ucloud/getting-started.md](https://github.com/amboltio/DM-i-AI-2025/blob/main/emergency-healthcare-rag/ucloud/getting-started.md)

### Offline LLM Frameworks

- **Ollama**, **llama.cpp**, **vLLM**, **Transformers** (Hugging Face)

### Performance Factors

Things like **model size**, **quantization** and **context length**, affect VRAM usage and inference speed.

## Acknowledgements

MD Caroline Schrøder for helping design the challenge
